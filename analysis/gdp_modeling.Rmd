---
title: "GDP Modeling"
author: "Stuart Miller"
date: "`r Sys.time()`"
output:
  github_document:
    toc: yes
    toc_depth: 6
  html_document:
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tswge)
library(gridExtra)
```

```{r, read-data, include=FALSE}
#read data with set columns
data <- read_csv('../data/economic_indicators_all_ex_3mo_china.csv',
                 col_types = cols(
                   date = col_character(),
                   gdp_change = col_double(),
                   unrate = col_double(),
                   nfjobs = col_double(),
                   treas10yr = col_double(),
                   treas3mo = col_double(),
                   treas10yr3mo = col_double(),
                   fedintrate = col_double(),
                   libor3mo = col_double(),
                   personincomechg = col_double(),
                   corpprofitchg = col_double()
                 )
              )
gdp <- data$gdp_change
```


# Univariate Modeling

## Plots

**Assess Constant Mean**

Based on the realization, it looks like there may be a slight downward trend.
This appears to be more pronounced prior to time step 75.
After time step 75, the movement of the realization appears to be more flat.
We will assume that the assumption of constant mean is not met.

**Assess Constant Variance**

The variance of the realization appears to be larger eariler in the realization (around and before 75).
Later in time, the variance of the realization appears to decrease.
Based on these observations and because only one realization is possible,
we will assume that the assumption of constant variance is not met.

**Assess Constant ACF**

The ACF of teh first half and the ACF of the second half appear to be different.
Both show expotentially dampped autocorrelations from 0,
but these autocorrelations fall off slower in the first half.
Additionally, the ACFs show different oscillator behavior.

**Conclusion**

Given the assessment of stationary above, 
we propose that this realization does not meet the requirements of a stationary process.

```{r}
vals <- plotts.sample.wge(gdp, lag.max = 50)

size = length(gdp)
acf(gdp[1:size/2], lag.max = 40)
acf(gdp[(size/2+1):(size-1)], lag.max = 40)
```

## ARMA Fit

### ARMA Order Selection by AIC/BIC

The following models are suggested by both AIC and BIC

* ARMA(2, 1)
* ARMA(1, 2)
* ARMA(3, 1)

```{r}
# should fits for AIC and BIC
bic_vals <- aic5.wge(gdp, type = 'bic')
aic_vals <- aic5.wge(gdp, type = 'aic')
cbind(bic_vals,aic_vals)
```

### Fit ARMA Model

A fit of the ARMA(2,1), which selected by AIC and BIC, as a root very close to one.
This is also a suggestion of a non-stationary series.

```{r}
est.arma <- est.arma.wge(gdp, 2, 1)
factor.wge(phi = est.arma$phi)
factor.wge(phi = est.arma$theta)
```


### Comparison of True Plots

The true plots of the model fit are shown below.
It is notable that the evidence of oscillation seen in the sample autocorrelation is not present in the true plots of the model fit.

```{r}
vals <- plotts.true.wge(n = length(gdp), phi = est.arma$phi, theta = est.arma$theta, lag.max = 50)
```


## ARIMA Fit

After taking the first difference, the only first autocorrelation appears to be significant.
This suggests that an MA(1) may be sufficient to explain the noise after the first difference.

```{r}
diff <- artrans.wge(data$gdp_change, phi.tr = 1, plottr = TRUE)
bic_vals <- aic5.wge(diff, type = 'bic')
aic_vals <- aic5.wge(diff, type = 'aic')
cbind(bic_vals,aic_vals)
```


```{r}
est.arima <- est.arma.wge(diff, 0, 1)
```


# Forecast The Models

## Forecast with a Sliding Window

* Window size: 12 (3 years)
* Validation size: 6 (1.5 years)
* Window step size: 6 (1.5 years)

```{r}
# control loop variables
n.head <- 6             # size of the validation forecast
window.size <- 12        # size of the rolling window (train and test)
                         # training size is `window.size - n.head + 1`
window.start.step <- 6  # size of the step to take between each iteration

# create dummy vactors ot hold ASE values
f1.mse.values <- c(1:19)
f2.mse.values <- c(1:19)

# collect the overall forecasts and limits
f1.fcast <- c(rep(NA,135))
f1.fcast.ul <- c(rep(NA,135))
f1.fcast.ll <- c(rep(NA,135))
f2.fcast <- c(rep(NA,135))
f2.fcast.ul <- c(rep(NA,135))
f2.fcast.ll <- c(rep(NA,135))

# roll over the realization
 for (i in seq(0, 30)){
   
   idx.start <- i * window.start.step + 1
   idx.end <- idx.start + window.size
   # forecast with f1
   f1 <- fore.aruma.wge(gdp[ idx.start : idx.end ],
                        phi = est.arma$phi,
                        theta = est.arma$theta, 
                        plot = F, 
                        n.ahead = n.head, 
                        lastn = T)
   
   # get the rolling forecast and limits
   for (j in seq(1, n.head)){
     f1.fcast[idx.end - n.head + j] <- f1$f[j]
     f1.fcast.ul[idx.end - n.head + j] <- f1$ul[j]
     f1.fcast.ll[idx.end - n.head + j] <- f1$ll[j]
   }
   
   # calculate ASE from f1 forecast
   f1.mse.values[i+1] <- mean( ( gdp[ (idx.end - n.head + 1) : idx.end ] - f1$f )^2 )
   
   # forecast with f2
   f2 <- fore.aruma.wge(gdp[ idx.start : idx.end ],
                        d = 1,
                        phi = 0,
                        theta = est.arima$theta, 
                        plot = F, 
                        n.ahead = n.head, 
                        lastn = T)
   
   # get the rolling forecast and limits
   for (j in seq(1, n.head)){
     f2.fcast[idx.end - n.head + j] <- f2$f[j]
     f2.fcast.ul[idx.end - n.head + j] <- f2$ul[j]
     f2.fcast.ll[idx.end - n.head + j] <- f2$ll[j]
   }
   
   # calculate ASE from f2 forecast
   f2.mse.values[i+1] <- mean( ( gdp[ (idx.end - n.head + 1) : idx.end ] - f2$f )^2 )
 }

# put the ASE values in a dataframe for plotting
model.res <- data.frame(
  ASE = c(f1.mse.values, f2.mse.values),
  Model = factor(c(rep('Model 1',length(f1.mse.values)),rep('Model 2',length(f2.mse.values))))
)

# just formatting the data to make the plot easier
f1.data <- data.frame(
  Realization = gdp[seq_along(f1.fcast)],
  Forecast = f1.fcast,
  UpperLimit = f1.fcast.ul,
  LowerLimit = f1.fcast.ll,
  Time = seq_along(f1.fcast),
  Model = rep('Model 1',length(f1.fcast))
)
f1.data <- gather(f1.data, Series, Value, Realization:LowerLimit, factor_key = T)

f2.data <- data.frame(
  Realization = gdp[seq_along(f2.fcast)],
  Forecast = f2.fcast,
  UpperLimit = f2.fcast.ul,
  LowerLimit = f2.fcast.ll,
  Time = seq_along(f2.fcast),
  Model = rep('Model 2',length(f2.fcast))
)
f2.data <- gather(f2.data, Series, Value, Realization:LowerLimit, factor_key = T)
f1f2 <- rbind(f1.data, f2.data)

print(paste('The mean ASE for model 1:', mean(f1.mse.values)))
print(paste('The mean ASE for model 2:', mean(f2.mse.values)))

```

## Compare ASE Values

The ASE values from the two models appear to be very similar.
The outlying error (approximately 22), is the large dip in the series, which both models miss.

```{r}
p1 <- data.frame(
  Model = as.factor(c(rep('Model.1', length(f1.mse.values)),
                      rep('Model.2', length(f2.mse.values)))),
  ASE = c(f1.mse.values, f2.mse.values)
) %>%
  ggplot(aes(y = ASE)) +
  geom_boxplot() +
  facet_wrap(~ Model) +
  ggtitle('Boxplots of ASEs') +
  xlab('Model')

p2 <- data.frame(
  Model.1.ASE = f1.mse.values,
  Model.2.ASE = f2.mse.values
) %>%
  ggplot(aes(y = f1.mse.values, x = f2.mse.values)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  ggtitle('Model ASE Correlation') +
  xlab('Model 2 ASE Values') +
  ylab('Model 1 ASE Values')

grid.arrange(p1, p2, ncol = 2, top = 'Model ASE Plots')
```


## Forecast Plots

In the plots below, model 1 is the ARMA(2,1) model and model 2 is the ARIMA(0,1,1) model.
The forecasts begin at the vertical line `t =` `r window.size - n.head + 2`.

```{r, fig.width=15, message=FALSE, warning=FALSE}
ggplot(f1f2, aes(y = Value, x = Time, col = Series)) +
  geom_line() +
  facet_wrap(~ Model, dir = 'v') + 
  geom_vline(xintercept = window.size - n.head + 2) +
  #geom_text(aes(x=27, label="\nForecast", y=7000), colour="blue", angle=0, size = 6) +
  #geom_text(aes(x=13, label="\nInitial\nTraining", y=7000), colour="blue", angle=0, size = 6) +
  labs(title = 'Forecasts and Prediction Limits for Model 1 & 2') +
  theme(plot.title = element_text(hjust = 0.5))
```

### Forecast Conclusion

The ARIMA(0,1,1) model generally appears to capture the movement of the realization better than the ARMA(2,1) model.
The ARMA model appear to have forecast jumps that are not consistent with the realization;
the ARIMA model does not exhibit this behavior.
The prediction bounds of the ARIMA model also appear to show more confidence on the movement of the realization.

**Rolling Window Validation Results**

| Model | ASE |
|-------|-----|
| ARMA(2,1) | 18.35 |
| ARIMA(0,1,1) | 13.24 |

The ARIMA model appears to be a better model of the realization than the ARMA model.
